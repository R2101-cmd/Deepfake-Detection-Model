{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c54a382",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install kaggle tensorflow numpy opencv-python matplotlib\n",
    "\n",
    "# Import necessary libraries\n",
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fa5472",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254d7b1f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Create directory\n",
    "os.makedirs(\"/root/.kaggle\", exist_ok=True)\n",
    "\n",
    "# Move kaggle.json\n",
    "shutil.move(\"kaggle.json\", \"/root/.kaggle/\")\n",
    "\n",
    "# Change permission\n",
    "os.chmod(\"/root/.kaggle/kaggle.json\", 600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930d7147",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!kaggle datasets list -s \"real-and-fake-face-detection\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8790a44e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Authenticate Kaggle API\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "# Download the dataset\n",
    "!kaggle datasets download -d ciplab/real-and-fake-face-detection -p /content/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060189c1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Define paths\n",
    "DOWNLOAD_PATH = \"/content/\"\n",
    "EXTRACTION_PATH = \"/content/real_fake_faces\"\n",
    "\n",
    "# Extract dataset\n",
    "zip_files = [f for f in os.listdir(DOWNLOAD_PATH) if f.endswith('.zip')]\n",
    "for file in zip_files:\n",
    "    with zipfile.ZipFile(os.path.join(DOWNLOAD_PATH, file), 'r') as zip_ref:\n",
    "        zip_ref.extractall(EXTRACTION_PATH)\n",
    "\n",
    "print(\"✅ Dataset extracted successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c922d3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Paths\n",
    "EXTRACTED_PATH = \"/content/real_fake_faces\"\n",
    "DATASET_FOLDER_1 = os.path.join(EXTRACTED_PATH, \"real_and_fake_face\")\n",
    "DATASET_FOLDER_2 = os.path.join(EXTRACTED_PATH, \"real_and_fake_face_detection\")\n",
    "\n",
    "# Define new structured dataset path\n",
    "MAIN_DATASET_PATH = \"/content/structured_deepfake_dataset\"\n",
    "REAL_PATH = os.path.join(MAIN_DATASET_PATH, \"real\")\n",
    "FAKE_PATH = os.path.join(MAIN_DATASET_PATH, \"fake\")\n",
    "\n",
    "# Ensure folders exist\n",
    "os.makedirs(REAL_PATH, exist_ok=True)\n",
    "os.makedirs(FAKE_PATH, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b83a084",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Move images based on dataset structure\n",
    "for dataset_folder in [DATASET_FOLDER_1, DATASET_FOLDER_2]:\n",
    "    for subfolder in os.listdir(dataset_folder):\n",
    "        subfolder_path = os.path.join(dataset_folder, subfolder)\n",
    "\n",
    "        if \"real\" in subfolder.lower():\n",
    "            for file in os.listdir(subfolder_path):\n",
    "                shutil.move(os.path.join(subfolder_path, file), REAL_PATH)\n",
    "\n",
    "        elif \"fake\" in subfolder.lower():\n",
    "            for file in os.listdir(subfolder_path):\n",
    "                shutil.move(os.path.join(subfolder_path, file), FAKE_PATH)\n",
    "\n",
    "print(\" Dataset is now structured into 'real/' and 'fake/' folders!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d314323",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Real images count:\", len(os.listdir(REAL_PATH)))\n",
    "print(\"Fake images count:\", len(os.listdir(FAKE_PATH)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0796af8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "train_data = datagen.flow_from_directory(\n",
    "    MAIN_DATASET_PATH, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='binary', subset='training'\n",
    ")\n",
    "\n",
    "val_data = datagen.flow_from_directory(\n",
    "    MAIN_DATASET_PATH, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='binary', subset='validation'\n",
    ")\n",
    "\n",
    "print(\"Dataset loaded successfully for training!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f994d8e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Create Kaggle API directory\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "# Download dataset\n",
    "!kaggle datasets download -d ciplab/real-and-fake-face-detection -p /content/\n",
    "\n",
    "# Extract dataset\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "EXTRACTION_PATH = \"/content/real_fake_faces\"\n",
    "\n",
    "zip_files = [f for f in os.listdir(\"/content/\") if f.endswith('.zip')]\n",
    "for file in zip_files:\n",
    "    with zipfile.ZipFile(os.path.join(\"/content/\", file), 'r') as zip_ref:\n",
    "        zip_ref.extractall(EXTRACTION_PATH)\n",
    "\n",
    "print(\"Dataset downloaded and extracted!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cbf49e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Paths\n",
    "DATASET_FOLDER_1 = os.path.join(EXTRACTION_PATH, \"real_and_fake_face\")\n",
    "DATASET_FOLDER_2 = os.path.join(EXTRACTION_PATH, \"real_and_fake_face_detection\")\n",
    "\n",
    "# New structured dataset path\n",
    "MAIN_DATASET_PATH = \"/content/structured_deepfake_dataset\"\n",
    "REAL_PATH = os.path.join(MAIN_DATASET_PATH, \"real\")\n",
    "FAKE_PATH = os.path.join(MAIN_DATASET_PATH, \"fake\")\n",
    "\n",
    "# Ensure folders exist\n",
    "os.makedirs(REAL_PATH, exist_ok=True)\n",
    "os.makedirs(FAKE_PATH, exist_ok=True)\n",
    "\n",
    "# Move images safely\n",
    "def move_files(dataset_folder, category, target_path):\n",
    "    subfolder_path = os.path.join(dataset_folder, category)\n",
    "\n",
    "    if not os.path.exists(subfolder_path):\n",
    "        return\n",
    "\n",
    "    for file in os.listdir(subfolder_path):\n",
    "        src_file = os.path.join(subfolder_path, file)\n",
    "        dst_file = os.path.join(target_path, file)\n",
    "\n",
    "        # Avoid duplicate errors\n",
    "        if os.path.exists(dst_file):\n",
    "            base, ext = os.path.splitext(file)\n",
    "            new_filename = f\"{base}_copy{ext}\"  # Rename duplicate files\n",
    "            dst_file = os.path.join(target_path, new_filename)\n",
    "\n",
    "        shutil.move(src_file, dst_file)\n",
    "\n",
    "# Move files from both dataset folders\n",
    "for dataset_folder in [DATASET_FOLDER_1, DATASET_FOLDER_2]:\n",
    "    for category in os.listdir(dataset_folder):\n",
    "        if \"real\" in category.lower():\n",
    "            move_files(dataset_folder, category, REAL_PATH)\n",
    "        elif \"fake\" in category.lower():\n",
    "            move_files(dataset_folder, category, FAKE_PATH)\n",
    "\n",
    "print(\"✅ Dataset structured successfully without duplicate errors!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a144257",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Image settings\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Data Augmentation\n",
    "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "# Load Training Data\n",
    "train_data = datagen.flow_from_directory(\n",
    "    MAIN_DATASET_PATH, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='binary', subset='training'\n",
    ")\n",
    "\n",
    "# Load Validation Data\n",
    "val_data = datagen.flow_from_directory(\n",
    "    MAIN_DATASET_PATH, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='binary', subset='validation'\n",
    ")\n",
    "\n",
    "print(\"✅ Data loaded successfully!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4fb951",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "\n",
    "# Load EfficientNetB0 as base model\n",
    "base_model = EfficientNetB0(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False  # Freeze base model layers\n",
    "\n",
    "# Build classifier\n",
    "model = keras.Sequential([\n",
    "    base_model,\n",
    "    keras.layers.GlobalAveragePooling2D(),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(1, activation='sigmoid')  # Binary classification (Real vs Fake)\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(\"✅ Model built successfully!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f637e1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "history = model.fit(train_data, validation_data=val_data, epochs=EPOCHS)\n",
    "\n",
    "# Save model for future use\n",
    "model.save(\"/content/deepfake_detector.h5\")\n",
    "\n",
    "print(\"✅ Model trained and saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486d9b06",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Accuracy plot\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.title(\"Training Accuracy\")\n",
    "plt.show()\n",
    "\n",
    "# Loss plot\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.title(\"Training Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a33dd4b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load trained model\n",
    "model = tf.keras.models.load_model(\"/content/model.h5\")  # Ensure the correct model path\n",
    "\n",
    "def predict_image(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "    img = cv2.resize(img, (128, 128))  # Resize to model input size\n",
    "    img = img.astype(\"float32\") / 255.0  # Normalize\n",
    "    img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "\n",
    "    prediction = model.predict(img)[0][0]\n",
    "    label = \"Fake\" if prediction > 0.5 else \"Real\"\n",
    "    print(f\"Prediction: {label} (Confidence: {prediction:.2f})\")\n",
    "\n",
    "# Test with an image\n",
    "predict_image(\"/content/real_00140.jpg\")  # Replace with your image path\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f2e353",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Function to predict if an image is real or fake\n",
    "def predict_image(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.resize(img, IMG_SIZE[::-1])  # OpenCV uses (width, height)\n",
    "    img = np.expand_dims(img, axis=0) / 255.0\n",
    "    prediction = model.predict(img)[0][0]\n",
    "    label = \"Fake\" if prediction  > 0.76 else \"Real\"\n",
    "    print(f\"Prediction: {label} (Confidence: {prediction:.2f})\")\n",
    "\n",
    "# Test with an image\n",
    "predict_image(\"/content/real_00140.jpg\")  # Replace with your image path\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4895fd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
